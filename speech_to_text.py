#!/usr/bin/python3
# All-in-one version

import os
import re
import sys
import configparser
import torch
import signal
import logging
from datetime import datetime
from pydub import AudioSegment
from pathlib import Path
# from concurrent.futures import ThreadPoolExecutor, as_completed
# from colorama import init, Fore, Style
# print(f"{Fore.RED}‚ùå Required parameters missing in settings.ini:{Style.RESET_ALL}")

class ConfigParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, config_path="settings.ini"):
        self.config = configparser.ConfigParser()
        self.config.read(config_path)
        self._parse_config()
    
    def _parse_config(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.audio_folder           = self.config["OPTIONS"]["sources_dir"]
        self.engine_name            = self.config["OPTIONS"].get("transcribe_engine", "").strip()
        self.whisper_model          = self.config["OPTIONS"].get("whisper_model", "").strip()
        self.text_language          = self.config["OPTIONS"].get("force_transcribe_language", "").strip()
        self.text_language          = self.text_language if self.text_language else None
        self.model_path             = self.config["OPTIONS"].get("model_path", "./models/").strip()
        self.skip_transcoded_files  = self._parse_bool(self.config["OPTIONS"].get("skip_transcoded_files"), default=False)
#        self.enable_logging         = self.config["OPTIONS"].get("logging", "0") == "1"
#        self.decode_to_wav          = self.config["OPTIONS"].get("decode_to_wav", "0") == "1"
#        self.use_cuda               = self.config["OPTIONS"].get("use_cuda", "1") == "1"
#        self.max_workers = int(config["OPTIONS"].get("max_workers", "1"))

        if not self.engine_name or not self.whisper_model:
            print("‚ùå Required parameters missing in settings.ini:")
            print("   - transcribe_engine (faster-whisper or openai-whisper)")
            print("   - whisper_model (tiny, base, small, medium, large)")
            print("\nUsage: python3 {os.path.basename(sys.argv[0])} [audio_folder_path]")
            sys.exit(1)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        self._parse_transcribe_params()

    def _parse_transcribe_params(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        transcribe_section = self.config["TRANSCRIBE"]
        
        self.beam_size = self._parse_int(transcribe_section.get("beam_size"), default=None)
        
        temperature_raw = transcribe_section.get("temperature", "").strip()
        if ',' in temperature_raw:
            self.temperature = self._parse_list_of_floats(temperature_raw, default=None)
        else:
            self.temperature = self._parse_float(temperature_raw, default=None)
            
        self.condition_on_prev_tokens = self._parse_bool(transcribe_section.get("condition_on_prev_tokens"), default=None)
        self.initial_prompt = transcribe_section.get("initial_prompt", "").strip() or None
        self.compression_ratio_threshold = self._parse_float(transcribe_section.get("compression_ratio_threshold"), default=None)
        self.logprob_threshold = self._parse_float(transcribe_section.get("logprob_threshold"), default=None)
        self.no_speech_threshold = self._parse_float(transcribe_section.get("no_speech_threshold"), default=None)
        self.patience = self._parse_float(transcribe_section.get("patience"), default=None)
        self.length_penalty = self._parse_float(transcribe_section.get("length_penalty"), default=None)
        self.suppress_blank = self._parse_bool(transcribe_section.get("suppress_blank"), default=None)
        
        suppress_tokens_raw = transcribe_section.get("suppress_tokens", "").strip()
        self.suppress_tokens = self._parse_list_of_ints(suppress_tokens_raw, default=None)
        
        self.without_timestamps = self._parse_bool(transcribe_section.get("without_timestamps"), default=None)
        self.max_initial_timestamp = self._parse_float(transcribe_section.get("max_initial_timestamp"), default=None)
        self.fp16 = self._parse_bool(transcribe_section.get("fp16"), default=None)
        self.temperature_increment_on_fallback = self._parse_float(transcribe_section.get("temperature_increment_on_fallback"), default=None)
    
    @staticmethod
    def _parse_float(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç float –∏–∑ —Å—Ç—Ä–æ–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        try:
            return float(value)
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ float. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default
    
    @staticmethod
    def _parse_int(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç int –∏–∑ —Å—Ç—Ä–æ–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        try:
            return int(value)
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ int. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default
    
    @staticmethod
    def _parse_bool(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç bool –∏–∑ —Å—Ç—Ä–æ–∫–∏ ('true', 'false'), –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        value_lower = value.lower().strip()
        if value_lower in ('true', '1', 'yes', 'on'):
            return True
        elif value_lower in ('false', '0', 'no', 'off'):
            return False
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ bool. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default
    
    @staticmethod
    def _parse_list_of_floats(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ float –∏–∑ —Å—Ç—Ä–æ–∫–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–ø—è—Ç—ã–º–∏."""
        if not value:
            return default
        try:
            return [float(item.strip()) for item in value.split(',') if item.strip()]
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —Å–ø–∏—Å–æ–∫ float. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default
    
    @staticmethod
    def _parse_list_of_ints(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ int –∏–∑ —Å—Ç—Ä–æ–∫–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–ø—è—Ç—ã–º–∏."""
        if not value:
            return default
        try:
            return [int(item.strip()) for item in value.split(',') if item.strip()]
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —Å–ø–∏—Å–æ–∫ int. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

class AudioProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self, config):
        self.config = config
        self.audio_exts = ['mp3', 'aac', 'ogg', 'wav', 'opus', 'flac', 'm4a', 'wma', 'aiff', 'amr']
        self.model = None
        self.start_time = None
        
         # –ü–æ–ª—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        self.current_audio_path = None
        self.current_dirname = None
        self.current_basename = None
        self.current_name_noext = None
        self.current_relative_path = None
        self.current_timecode_file = None
        self.current_rawtext_file = None
        self.current_error_file = None

    def _setup_file_paths(self, audio_path):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        self.current_audio_path = audio_path
        self.current_dirname = os.path.dirname(audio_path)
        self.current_basename = os.path.basename(audio_path)
        self.current_name_noext = os.path.splitext(self.current_basename)[0]
        self.current_relative_path = Path(audio_path).relative_to(self.current_dirname)

        self.current_timecode_file = os.path.join(self.current_dirname, self.current_name_noext + '_timecodes.txt')
        self.current_rawtext_file = os.path.join(self.current_dirname, self.current_name_noext + '_raw.txt')
        self.current_error_file = os.path.join(self.current_dirname, self.current_name_noext + '_ERROR.txt')
     
    def initialize_engine(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        engine_name = self.config.engine_name
        whisper_model = self.config.whisper_model
        model_path = os.path.join(self.config.model_path, "openai-whisper")
        
        if engine_name == "openai-whisper":
            import whisper
            print(f'Loading model: "{whisper_model}" using engine: {engine_name}...')
            self.model = whisper.load_model(
                whisper_model,
                device="cuda" if torch.cuda.is_available() else "cpu",
                download_root=model_path
            )
        else:
            raise ValueError(f"Unknown transcribe_engine: '{engine_name}'. Use 'openai-whisper'.")
        
        print('‚úÖ Model loaded.\n')

    def should_skip_file(self, audio_path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–ª"""
        # –ï—Å–ª–∏ –æ–ø—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞, –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã
        if not self.config.skip_transcoded_files:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(self.current_timecode_file) and os.path.exists(self.current_rawtext_file):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–æ–≤–µ–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ
            try:
                audio_mtime = os.path.getmtime(audio_path)
                timecode_mtime = os.path.getmtime(self.current_timecode_file)
                rawtext_mtime = os.path.getmtime(self.current_rawtext_file)

                # –§–∞–π–ª –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ –æ–±–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞ –Ω–æ–≤–µ–µ –≤—Ö–æ–¥–Ω–æ–≥–æ
                if timecode_mtime > audio_mtime and rawtext_mtime > audio_mtime:
                    return True
            except OSError:
                # –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª
                return False

        return False

    def find_audio_files(self):
        """–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        audio_folder = self.config.audio_folder
        print(f'Scanning "{audio_folder}" (including subdirectories)...')
        
        if not os.path.exists(audio_folder):
            print(f'‚ùå Directory not found: "{audio_folder}"')
            return []
        
        audio_files = []
        for root, dirs, files in os.walk(audio_folder):
            for file in files:
                if self._match_ext(file, self.audio_exts):
                    full_path = os.path.join(root, file)
                    audio_files.append(full_path)
        
        return audio_files

    def get_file_info(self, audio_path):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ: —Ä–∞–∑–º–µ—Ä –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
        file_size = os.path.getsize(audio_path)

        try:
            audio = AudioSegment.from_file(audio_path)
            duration = len(audio) / 1000.0
            print(f'    Duration: {self._format_time(duration)}')
        except Exception:
            print(f'    ‚ö†Ô∏è Could not read duration: {audio_path}')
            duration = 0

        return file_size, duration

    def process_all_files(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
        self.start_time = datetime.now()
        audio_files = self.find_audio_files()
        total_files = len(audio_files)
        
        if total_files == 0:
            print('No audio files found to process.')
            return
        
        print(f'‚úÖ Found {total_files} audio file(s) to process.\n')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–æ–∫ –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.initialize_engine()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        for idx, audio_file in enumerate(audio_files, 1):
            self._process_audiofile_openai_whisper(audio_file, idx, total_files)
        
        print('‚úÖ All files processed.')
        print(f'‚úÖ Total time: {self._format_elapsed_time(datetime.now() - self.start_time)}')
        print()
   
    def _process_audiofile_openai_whisper(self, audio_path, file_index, total_files):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º openai-whisper"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(audio_path):
            print(f'[{file_index:3d}/{total_files}] ‚ùå File not found: {audio_path}')
            return

        file_start_time = datetime.now()

        # –ü—É—Ç–∏ –∫ –≤—ã—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–∞–º
        self._setup_file_paths(audio_path)

        print(f'[{file_index:3d}/{total_files}] Processing: {self.current_relative_path}')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è)
        if self.should_skip_file(audio_path):
            print(f'[{file_index:3d}/{total_files}] ‚è≠Ô∏è Skipping (already processed)')
            print()
            return

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        filesize, duration = self.get_file_info(audio_path)

        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è openai-whisper
            transcribe_kwargs = {
                "verbose": False,
                "language": self.config.text_language,
                "temperature": self.config.temperature,
                "condition_on_previous_text": self.config.condition_on_prev_tokens,
                "initial_prompt": self.config.initial_prompt,
                "compression_ratio_threshold": self.config.compression_ratio_threshold,
                "logprob_threshold": self.config.logprob_threshold,
                "no_speech_threshold": self.config.no_speech_threshold,
                "patience": self.config.patience,
                "length_penalty": self.config.length_penalty,
                "suppress_blank": self.config.suppress_blank,
                "suppress_tokens": self.config.suppress_tokens,
                "without_timestamps": self.config.without_timestamps,
                "max_initial_timestamp": self.config.max_initial_timestamp,
                "fp16": self.config.fp16,
            }
            
            # –ï—Å–ª–∏ beam_size –∑–∞–¥–∞–Ω–æ, –ø–µ—Ä–µ–¥–∞–µ–º –µ–≥–æ
            if self.config.beam_size is not None:
                transcribe_kwargs["beam_size"] = self.config.beam_size
            
            # –£–¥–∞–ª—è–µ–º –∫–ª—é—á–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º None
            transcribe_kwargs = {k: v for k, v in transcribe_kwargs.items() if v is not None}
            
            print(f"    Starting transcription with openai-whisper (model: {self.config.whisper_model})...")
            result = self.model.transcribe(audio_path, **transcribe_kwargs)
            
            # –û—Ü–µ–Ω–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if duration == 0 and 'segments' in result and len(result['segments']) > 0:
                duration = result['segments'][-1]['end']
                print("    Transcribing... (duration estimated)")
            else:
                print(f"    Transcribing... (duration: {self._format_time(duration)})")
            
            full_text = []
            with open(self.current_timecode_file, 'w', encoding='UTF-8') as f:
                for i, segment in enumerate(result['segments']):
                    start = segment['start']
                    end = segment['end']
                    text = segment['text'].strip()
                    hh, mm, ss = int(start // 3600), int((start % 3600) // 60), int(start % 60)
                    f.write(f"[{hh:02d}:{mm:02d}:{ss:02d}] {text}\n")
                    full_text.append(text)
                    # —Å–∫—Ä—ã–≤–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–π progress bar —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
#                    if duration > 0:
#                        self._print_progress_bar(end, duration)

#           —Å–∫—Ä—ã–≤–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–π progress bar —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
#            if duration > 0:
#                self._print_progress_bar(duration, duration)
#            print()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
            self._save_text_files(full_text, self.current_rawtext_file)
            
            print(f'‚úÖ Done in {self._format_elapsed_time(datetime.now() - file_start_time)}')
            print()
        
        except Exception as e:
            print(f'\n‚ùå Error processing {audio_path}: {e}')
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –≤ —Ñ–∞–π–ª
            with open(self.current_error_file, 'w', encoding='UTF-8') as ef:
                ef.write(f"Error processing {audio_path}: {e}\n")
    
    def _save_text_files(self, full_text, rawtext_file):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤"""

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
        rawtext = ' '.join(full_text)
        rawtext = re.sub(r" +", " ", rawtext)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        alltext = re.sub(r"([.!?])\s+", r"\1\n", rawtext)
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
        alltext = alltext.strip()
        
        with open(rawtext_file, 'w', encoding='UTF-8') as f:
            f.write(alltext)
    
    @staticmethod
    def _format_time(seconds):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏"""
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"

    @staticmethod
    def _format_elapsed_time(elapsed_time):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–µ–∑ –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏ —Å–µ–∫—É–Ω–¥"""
        return str(elapsed_time).split('.')[0]

    def _print_progress_bar(self, current, total, bar_length=30):
        """–í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ (–ª–∏—à–Ω–µ–≥–æ) """
        if total <= 0:
            return
        fraction = current / total
        filled = int(bar_length * fraction)
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        print(f'\r    Progress: |{bar}| {fraction:.1%} ({self._format_time(current)}/{self._format_time(total)})', end='', flush=True)
    
    @staticmethod
    def _match_ext(filename, extensions):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞"""
        ext = filename.lower().split('.')[-1]
        return ext in extensions

class AudioTranscriber:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ"""

    def _print_copyright(self):
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ø–∏—Ä–∞–π—Ç–µ"""
        print("=" * 50)
        print("Audio Transcriber v1.0")
        print("Based on OpenAI Whisper")
        print("=" * 50)
        print()

    def _print_gpu_info(self):
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ –∏ —Ä–µ–∂–∏–º–µ CUDA"""
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_count = torch.cuda.device_count()
            print(f"üöÄ CUDA enabled: {gpu_count} GPU(s) available")
            print(f"   GPU: {gpu_name}")
            print(f"   CUDA version: {torch.version.cuda}")
#            print(f"   CUDA architecture: {torch.cuda.get_arch_list()}")
        else:
            print("üíª CUDA disabled: using CPU only")
        print()

    def setup_logging(enabled):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if enabled:
            logging.basicConfig(
                filename='transcription.log',
                level=logging.INFO,
                format='%(asctime)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )

    def __init__(self):
        self._print_copyright()
        self._print_gpu_info()
        self.config = ConfigParser()
        self.processor = AudioProcessor(self.config)

    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            self.processor.process_all_files()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")
            return False
        return True

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
shutdown_requested = False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    app = AudioTranscriber()
    app.run()

def signal_handler(sig, frame):
    global shutdown_requested
    print('\n\n‚ö†Ô∏è Shutdown requested. Finishing current tasks...')
    shutdown_requested = True

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ Ctrl+C
# signal.signal(signal.SIGINT, signal_handler)

# .entrypoint
if __name__ == '__main__':
    main()
