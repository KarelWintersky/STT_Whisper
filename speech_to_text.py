#!/usr/bin/python3
# All-in-one version

import os
import re
import sys
import configparser
import torch
import warnings
import signal
import logging
from datetime import datetime
from pydub import AudioSegment
from pathlib import Path

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ—Ç whisper
warnings.filterwarnings("ignore", message="Performing inference on CPU when CUDA is available")

# ------------------------------------------------------------------------- #

class Helper:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å —Å —É—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""

    @staticmethod
    def format_time(seconds):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏"""
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"

    @staticmethod
    def format_elapsed_time(elapsed_time):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–µ–∑ –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏ —Å–µ–∫—É–Ω–¥"""
        return str(elapsed_time).split('.')[0]

    @staticmethod
    def format_srt_timestamp(seconds):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è SRT (–ß–ß:–ú–ú:–°–°,–º–º–º)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

    @staticmethod
    def match_ext(filename, extensions):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞"""
        ext = filename.lower().split('.')[-1]
        return ext in extensions

    @staticmethod
    def parse_float(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç float –∏–∑ —Å—Ç—Ä–æ–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        try:
            return float(value)
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ float. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

    @staticmethod
    def parse_int(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç int –∏–∑ —Å—Ç—Ä–æ–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        try:
            return int(value)
        except ValueError:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ int. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

    @staticmethod
    def parse_bool(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç bool –∏–∑ —Å—Ç—Ä–æ–∫–∏ ('true', 'false'), –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default –µ—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è."""
        if not value:
            return default
        value_lower = value.lower().strip()
        if value_lower in ('true', '1', 'yes', 'on'):
            return True
        elif value_lower in ('false', '0', 'no', 'off'):
            return False
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ bool. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

    @staticmethod
    def parse_list_of_floats(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ float –∏–∑ —Å—Ç—Ä–æ–∫–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–ø—è—Ç—ã–º–∏."""
        if not value:
            return default
        try:
            return [float(item.strip()) for item in value.split(',') if item.strip()]
        except ValueError:
            print(
                f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —Å–ø–∏—Å–æ–∫ float. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

    @staticmethod
    def parse_list_of_ints(value, default=None):
        """–ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ int –∏–∑ —Å—Ç—Ä–æ–∫–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞–ø—è—Ç—ã–º–∏."""
        if not value:
            return default
        try:
            return [int(item.strip()) for item in value.split(',') if item.strip()]
        except ValueError:
            print(
                f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —Å–ø–∏—Å–æ–∫ int. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            return default

    @staticmethod
    def print_total_stats(processed_files_count, total_duration, total_processing_time):
        """–í—ã–≤–æ–¥ —Å—É–º–º–∞—Ä–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if processed_files_count > 0:
            speed_ratio = total_duration / total_processing_time if total_processing_time > 0 else 0
            print(f"\nüìä Total statistics:")
            print(f"  üïê Audio duration: {Helper.format_time(total_duration)}")
            print(f"  ‚è±Ô∏è Processing time: {Helper.format_time(total_processing_time)}")
            print(f"  ‚ö° Speed ratio: {speed_ratio:.2f}x")
        else:
            print("\nNo files were processed.")

    @staticmethod
    def print_progress_bar(current, total, bar_length=30):
        """–í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ (–ª–∏—à–Ω–µ–≥–æ) """
        if total <= 0:
            return
        fraction = current / total
        filled = int(bar_length * fraction)
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        print(f'\r    Progress: |{bar}| {fraction:.1%} ({Helper.format_time(current)}/{Helper.format_time(total)})', end='', flush=True)

    @staticmethod
    def save_timecode_file(result, timecode_file):
        full_text = []

        with open(timecode_file, 'w', encoding='UTF-8') as f:
            for i, segment in enumerate(result['segments']):
                start = segment['start']
                end = segment['end']
                text = segment['text'].strip()
                hh, mm, ss = int(start // 3600), int((start % 3600) // 60), int(start % 60)
                f.write(f"[{hh:02d}:{mm:02d}:{ss:02d}] {text}\n")
                full_text.append(text)

        return full_text

    @staticmethod
    def save_text_files(full_text, rawtext_file):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤"""

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
        rawtext = ' '.join(full_text)
        rawtext = re.sub(r" +", " ", rawtext)

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        alltext = re.sub(r"([.!?])\s+", r"\1\n", rawtext)

        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
        alltext = alltext.strip()

        with open(rawtext_file, 'w', encoding='UTF-8') as f:
            f.write(alltext)

    @staticmethod
    def save_srt_file(result, srt_file_path):
        """–≠–∫—Å–ø–æ—Ä—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤"""
        try:
            with open(srt_file_path, 'w', encoding='UTF-8') as f:
                for i, segment in enumerate(result['segments'], 1):
                    # –ù–æ–º–µ—Ä —Ç–∏—Ç—Ä–∞
                    f.write(f"{i}\n")

                    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                    start_time = Helper.format_srt_timestamp(segment['start'])
                    end_time = Helper.format_srt_timestamp(segment['end'])
                    f.write(f"{start_time} --> {end_time}\n")

                    # –¢–µ–∫—Å—Ç —Å—É–±—Ç–∏—Ç—Ä–∞
                    text = segment['text'].strip()
                    f.write(f"{text}\n")

                    # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏
                    f.write("\n")

            print(f"    SRT subtitles saved to: {os.path.basename(srt_file_path)}")

        except Exception as e:
            print(f"    ‚ö†Ô∏è Error exporting SRT: {e}")

# --------------------------------------------------------------------------------------------- #

class SSTLogger:
    """–ö–ª–∞—Å—Å –¥–ª—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""

    def __init__(self, enable_logging=False):
        self.enable_logging = enable_logging
        if self.enable_logging:
            self._setup_logging()

    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            filename='transcription.log',
            level=logging.INFO,
            format='%(asctime)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            encoding='utf-8'
        )

    def log_message(self, message):
        """–õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        if self.enable_logging:
            logging.info(message)

    def log_session_start(self, engine_name, model_name, device):
        """–õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–∞—á–∞–ª–µ —Å–µ—Å—Å–∏–∏"""
        if self.enable_logging:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CUDA
            if device == "cuda" and torch.cuda.is_available():
                gpu_info = f"{torch.cuda.get_device_name(0)} (CUDA {torch.version.cuda})"
            else:
                gpu_info = "None"

            session_info = f"""
        SESSION STARTED
          Engine: {engine_name}
          Model: {model_name}
          Device: {device}
          GPU: {gpu_info}
          CUDA available: {torch.cuda.is_available()}
        """
            self.log_message(session_info.strip())

    def log_session_summary(self, processed_files_count, successful_files_count, failed_files_count, total_duration, total_processing_time, session_time):
        """–õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–µ—Å—Å–∏–∏"""
        if self.enable_logging and processed_files_count > 0:
            speed_ratio = total_duration / total_processing_time if total_processing_time > 0 else 0
            summary = f"""
    SESSION SUMMARY:
      Files processed: {processed_files_count} (Success: {successful_files_count}, Failed: {failed_files_count})
      Total audio duration: {Helper.format_time(total_duration)}
      Total processing time: {Helper.format_time(total_processing_time)}
      Session time: {Helper.format_time(session_time)}
      Overall speed ratio: {speed_ratio:.2f}x
    """
            self.log_message(summary.strip())

# --------------------------------------------------------------------------------------------- #

class ConfigParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, config_path="settings.ini"):
        self.config = configparser.ConfigParser()
        self.config.read(config_path, encoding='utf-8')
        self._parse_config()
    
    def _parse_config(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.audio_folder           = self.config["OPTIONS"]["sources_dir"]
        self.engine_name            = self.config["OPTIONS"].get("transcribe_engine", "openai-whisper").strip()
        self.whisper_model          = self.config["OPTIONS"].get("whisper_model", "tiny").strip()
        self.text_language          = self.config["OPTIONS"].get("force_transcribe_language", "").strip()
        self.text_language          = self.text_language if self.text_language else None
        self.model_path             = self.config["OPTIONS"].get("model_path", "./models/").strip()
        self.skip_transcoded_files  = Helper.parse_bool(self.config["OPTIONS"].get("skip_transcoded_files"), default=False)
        self.use_cuda               = Helper.parse_bool(self.config["OPTIONS"].get("use_cuda", "1"), default=True)

        self.export_srt_file        = Helper.parse_bool(self.config["OPTIONS"].get("export_srt_file"), default=False)
        self.export_raw_file        = Helper.parse_bool(self.config["OPTIONS"].get("export_raw_file"), default=False)

        self.enable_logging         = Helper.parse_bool(self.config["OPTIONS"].get("logging", "0"), default=False)

#        self.decode_to_wav          = self.config["OPTIONS"].get("decode_to_wav", "0") == "1"
#        self.max_workers            = int(config["OPTIONS"].get("max_workers", "1"))

        if not self.engine_name or not self.whisper_model:
            print("‚ùå Required parameters missing in settings.ini:")
            print("   - transcribe_engine (faster-whisper or openai-whisper)")
            print("   - whisper_model (tiny, base, small, medium, large)")
            print("\nUsage: python3 {os.path.basename(sys.argv[0])}")
            sys.exit(1)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        self._parse_transcribe_params()

    def _parse_transcribe_params(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        transcribe_section = self.config["TRANSCRIBE"]
        
        self.beam_size = Helper.parse_int(transcribe_section.get("beam_size"), default=None)
        
        temperature_raw = transcribe_section.get("temperature", "").strip()
        if ',' in temperature_raw:
            self.temperature = Helper.parse_list_of_floats(temperature_raw, default=None)
        else:
            self.temperature = Helper.parse_float(temperature_raw, default=None)
            
        self.condition_on_prev_tokens = Helper.parse_bool(transcribe_section.get("condition_on_prev_tokens"), default=None)
        self.initial_prompt = transcribe_section.get("initial_prompt", "").strip() or None
        self.compression_ratio_threshold = Helper.parse_float(transcribe_section.get("compression_ratio_threshold"), default=None)
        self.logprob_threshold = Helper.parse_float(transcribe_section.get("logprob_threshold"), default=None)
        self.no_speech_threshold = Helper.parse_float(transcribe_section.get("no_speech_threshold"), default=None)
        self.patience = Helper.parse_float(transcribe_section.get("patience"), default=None)
        self.length_penalty = Helper.parse_float(transcribe_section.get("length_penalty"), default=None)
        self.suppress_blank = Helper.parse_bool(transcribe_section.get("suppress_blank"), default=None)
        
        suppress_tokens_raw = transcribe_section.get("suppress_tokens", "").strip()
        self.suppress_tokens = Helper.parse_list_of_ints(suppress_tokens_raw, default=None)
        
        self.without_timestamps = Helper.parse_bool(transcribe_section.get("without_timestamps"), default=None)
        self.max_initial_timestamp = Helper.parse_float(transcribe_section.get("max_initial_timestamp"), default=None)
        self.fp16 = Helper.parse_bool(transcribe_section.get("fp16"), default=None)
        self.temperature_increment_on_fallback = Helper.parse_float(transcribe_section.get("temperature_increment_on_fallback"), default=None)

# --------------------------------------------------------------------------------------------- #

class AudioProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self, config):
        self.config = config
        self.audio_exts = ['mp3', 'aac', 'ogg', 'wav', 'opus', 'flac', 'm4a', 'wma', 'aiff', 'amr']
        self.model = None
        self.start_time = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_duration = 0.0
        self.total_processing_time = 0.0
        self.processed_files_count = 0
        self.successful_files_count = 0
        self.failed_files_count = 0

        # –ü–æ–ª—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        self.current_audio_path = None
        self.current_dirname = None
        self.current_basename = None
        self.current_name_noext = None
        self.current_relative_path = None
        self.current_timecode_file = None
        self.current_rawtext_file = None
        self.current_error_file = None
        self.current_srt_file = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
        self.logger = SSTLogger(self.config.enable_logging)

    def _setup_file_paths(self, audio_path):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        self.current_audio_path = audio_path
        self.current_dirname = os.path.dirname(audio_path)
        self.current_basename = os.path.basename(audio_path)
        self.current_name_noext = os.path.splitext(self.current_basename)[0]
        self.current_relative_path = Path(audio_path).relative_to(self.config.audio_folder)

        self.current_timecode_file = os.path.join(self.current_dirname, self.current_name_noext + '_timecodes.txt')
        self.current_rawtext_file = os.path.join(self.current_dirname, self.current_name_noext + '_raw.txt')
        self.current_srt_file = os.path.join(self.current_dirname, self.current_name_noext + '.srt')
        self.current_error_file = os.path.join(self.current_dirname, self.current_name_noext + '_ERROR.txt')

    def initialize_engine(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        engine_name = self.config.engine_name
        whisper_model = self.config.whisper_model
        model_path = os.path.join(self.config.model_path, "openai-whisper")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if self.config.use_cuda and torch.cuda.is_available():
            device = "cuda"
            print("üöÄ Using CUDA for processing")
        else:
            device = "cpu"
            self.config.fp16 = False
            if self.config.use_cuda:
                print("‚ö†Ô∏è  CUDA enabled in config but not available, using CPU")
            else:
                print("üíª Using CPU for processing")

        print()

        if engine_name == "openai-whisper":
            import whisper
            print(f'Loading model: "{whisper_model}" using engine: {engine_name}...')
            self.model = whisper.load_model(
                whisper_model,
                device=device,
                download_root=model_path
            )
        else:
            raise ValueError(f"Unknown transcribe_engine: '{engine_name}'. Use 'openai-whisper'.")

        print('‚úÖ Model loaded.\n')
        self.logger.log_session_start(engine_name, whisper_model, device)

    def should_skip_file(self, audio_path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–ª"""
        if not self.config.skip_transcoded_files:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(self.current_timecode_file) and os.path.exists(self.current_rawtext_file):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–æ–≤–µ–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ
            try:
                audio_mtime = os.path.getmtime(audio_path)
                timecode_mtime = os.path.getmtime(self.current_timecode_file)
                rawtext_mtime = os.path.getmtime(self.current_rawtext_file)

                # –§–∞–π–ª –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ –æ–±–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞ –Ω–æ–≤–µ–µ –≤—Ö–æ–¥–Ω–æ–≥–æ
                if timecode_mtime > audio_mtime and rawtext_mtime > audio_mtime:
                    return True
            except OSError:
                # –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª
                return False

        return False

    def find_audio_files(self):
        """–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        audio_folder = self.config.audio_folder
        print(f'Scanning "{audio_folder}" (including subdirectories)...')
        
        if not os.path.exists(audio_folder):
            print(f'‚ùå Directory not found: "{audio_folder}"')
            return []
        
        audio_files = []
        for root, dirs, files in os.walk(audio_folder):
            for file in files:
                if Helper.match_ext(file, self.audio_exts):
                    full_path = os.path.join(root, file)
                    audio_files.append(full_path)
        
        return audio_files

    def get_file_info(self, audio_path):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ: —Ä–∞–∑–º–µ—Ä –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
        file_size = os.path.getsize(audio_path)

        try:
            audio = AudioSegment.from_file(audio_path)
            duration = len(audio) / 1000.0
            print(f'    Duration: {Helper.format_time(duration)}')
        except Exception:
            print(f'    ‚ö†Ô∏è Could not read duration: {audio_path}')
            duration = 0

        return file_size, duration

    def process_all_files(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
        self.start_time = datetime.now()
        audio_files = self.find_audio_files()
        total_files = len(audio_files)
        
        if total_files == 0:
            print('No audio files found to process.')
            return
        
        print(f'‚úÖ Found {total_files} audio file(s) to process.\n')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–æ–∫ –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.initialize_engine()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        for idx, audio_file in enumerate(audio_files, 1):
            self._process_audiofile_openai_whisper(audio_file, idx, total_files)
        
        print('‚úÖ All files processed.')
        # print(f'‚úÖ Total time: {Helper.format_elapsed_time(datetime.now() - self.start_time)}')
        Helper.print_total_stats(self.processed_files_count, self.total_duration, self.total_processing_time)
        self._log_session_summary()
        print()
   
    def _process_audiofile_openai_whisper(self, audio_path, file_index, total_files):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º openai-whisper"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(audio_path):
            print(f'[{file_index:3d}/{total_files}] ‚ùå File not found: {audio_path}')
            return

        file_start_time = datetime.now()

        # –ü—É—Ç–∏ –∫ –≤—ã—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–∞–º
        self._setup_file_paths(audio_path)

        print(f'[{file_index:3d}/{total_files}] Processing: {self.current_relative_path}')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if self.should_skip_file(audio_path):
            # print(f'[{file_index:3d}/{total_files}] ‚è≠Ô∏è Skipping (already processed)')
            print(" " * 9 + f'‚è≠Ô∏è Skipping (already processed)')
            print()
            return

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        filesize, duration = self.get_file_info(audio_path)

        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è openai-whisper
            transcribe_kwargs = {
                "verbose": False,
                "language": self.config.text_language,
                "temperature": self.config.temperature,
                "condition_on_previous_text": self.config.condition_on_prev_tokens,
                "initial_prompt": self.config.initial_prompt,
                "compression_ratio_threshold": self.config.compression_ratio_threshold,
                "logprob_threshold": self.config.logprob_threshold,
                "no_speech_threshold": self.config.no_speech_threshold,
                "patience": self.config.patience,
                "length_penalty": self.config.length_penalty,
                "suppress_blank": self.config.suppress_blank,
                "suppress_tokens": self.config.suppress_tokens,
                "without_timestamps": self.config.without_timestamps,
                "max_initial_timestamp": self.config.max_initial_timestamp,
                "fp16": self.config.fp16,
            }
            
            # –ï—Å–ª–∏ beam_size –∑–∞–¥–∞–Ω–æ, –ø–µ—Ä–µ–¥–∞–µ–º –µ–≥–æ
            if self.config.beam_size is not None:
                transcribe_kwargs["beam_size"] = self.config.beam_size
            
            # –£–¥–∞–ª—è–µ–º –∫–ª—é—á–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º None
            transcribe_kwargs = {k: v for k, v in transcribe_kwargs.items() if v is not None}
            
            print(f"    Starting transcription with openai-whisper (model: {self.config.whisper_model})...")
            result = self.model.transcribe(audio_path, **transcribe_kwargs)
            
            # –û—Ü–µ–Ω–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if duration == 0 and 'segments' in result and len(result['segments']) > 0:
                duration = result['segments'][-1]['end']
                print("    Transcribing... (duration estimated)")
            else:
                print(f"    Transcribing... (duration: {Helper.format_time(duration)})")

            full_text = Helper.save_timecode_file(result, self.current_timecode_file)

#           —Å–∫—Ä—ã–≤–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–π progress bar —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
#            if duration > 0:
#                Helper.print_progress_bar(duration, duration)
#            print()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
            if self.config.export_raw_file:
                Helper.save_text_files(full_text, self.current_rawtext_file)

            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º SRT —Å—É–±—Ç–∏—Ç—Ä—ã
            if self.config.export_srt_file:
                Helper.save_srt_file(result, self.current_srt_file)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            processing_time = (datetime.now() - file_start_time).total_seconds()
            self.total_duration += duration
            self.total_processing_time += processing_time
            self.processed_files_count += 1
            self.successful_files_count += 1

            # –õ–æ–≥–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            speed_ratio = processing_time / duration if duration > 0 else 0
            self.logger.log_message(
                f"SUCCESS: {audio_path} | Size: {filesize} bytes | Duration: {Helper.format_time(duration)} | Time: {Helper.format_time(processing_time)} | Speed: {speed_ratio:.2f}x")

            print(f'‚úÖ Done in {Helper.format_elapsed_time(datetime.now() - file_start_time)}')
            print()
        
        except Exception as e:
            print(f'\n‚ùå Error processing {audio_path}: {e}')
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –≤ —Ñ–∞–π–ª
            with open(self.current_error_file, 'w', encoding='UTF-8') as ef:
                ef.write(f"Error processing {audio_path}: {e}\n")

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫
            self.processed_files_count += 1
            self.failed_files_count += 1

            # –õ–æ–≥–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
            self.logger.log_message(
                f"ERROR: {audio_path} | Size: {filesize} bytes | Duration: {Helper.format_time(duration)} | Error: {str(e)}")

    def _log_session_summary(self):
        """–õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–µ—Å—Å–∏–∏"""
        if self.config.enable_logging and self.processed_files_count > 0:
            speed_ratio = self.total_duration / self.total_processing_time if self.total_processing_time > 0 else 0
            session_time = (datetime.now() - self.start_time).total_seconds()
            self.logger.log_session_summary(
                self.processed_files_count,
                self.successful_files_count,
                self.failed_files_count,
                self.total_duration,
                self.total_processing_time,
                session_time
            )


# --------------------------------------------------------------------------------------------- #

class AudioTranscriber:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ"""

    @staticmethod
    def _print_copyright():
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ø–∏—Ä–∞–π—Ç–µ"""
        print("=" * 50)
        print("Audio Transcriber v1.0")
        print("Based on OpenAI Whisper")
        print("=" * 50)
        print()

    @staticmethod
    def _print_gpu_info():
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ –∏ —Ä–µ–∂–∏–º–µ CUDA"""
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_count = torch.cuda.device_count()
            print(f"üöÄ CUDA enabled: {gpu_count} GPU(s) available")
            print(f"   GPU: {gpu_name}")
            print(f"   CUDA version: {torch.version.cuda}")
        else:
            print("üíª CUDA disabled: using CPU only")
        print()

    def __init__(self):
        self._print_copyright()
        self._print_gpu_info()
        self.config = ConfigParser()
        self.processor = AudioProcessor(self.config)

    def run(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            self.processor.process_all_files()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")
            return False
        return True

# --------------------------------------------------------------------------------------------- #

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
shutdown_requested = False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    app = AudioTranscriber()
    app.run()


def signal_handler(sig, frame):
    global shutdown_requested
    print('\n\n‚ö†Ô∏è Shutdown requested. Finishing current tasks...')
    shutdown_requested = True

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ Ctrl+C
# signal.signal(signal.SIGINT, signal_handler)

# .entrypoint
if __name__ == '__main__':
    main()

# -eof- #
